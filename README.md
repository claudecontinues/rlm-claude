# RLM - Recursive Language Models for Claude Code

> **Memoire infinie pour Claude** - Solution MCP avec auto-chunking 100% automatique

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## Le Probleme

Les LLMs souffrent de **degradation avec les contextes longs** :
- **Lost in the Middle** : Performance degradee sur les informations au milieu du contexte
- **Context Rot** : Degradation progressive (~60% = debut des problemes)
- Claude devient "lazy et dumb" au-dela de 60-65% de contexte

## La Solution : RLM

Inspire du paper **"Recursive Language Models"** (MIT CSAIL, arXiv:2512.24601, Dec 2025) :

1. **Contexte comme objet externe** - L'historique est stocke en fichiers, pas charge en memoire
2. **Tools de navigation** - Peek, grep, search au lieu de tout lire
3. **Memoire d'insights** - Decisions et faits cles sauvegardes separement
4. **Auto-chunking** - Sauvegarde automatique via hooks Claude Code
5. **Sub-agents** - Deleguer des analyses a des workers isoles

---

## Installation Rapide

```bash
# 1. Cloner le repo
git clone https://github.com/EncrEor/rlm-claude.git
cd rlm-claude

# 2. Installer (100% automatique)
./install.sh

# 3. Relancer Claude Code
# RLM est pret !
```

**Prerequis** : Python 3.10+, Claude Code CLI

### Installation Manuelle

Si vous preferez installer manuellement :

```bash
# Installer les dependances
pip install -r mcp_server/requirements.txt

# Ajouter le serveur MCP
claude mcp add rlm-server -- python3 $(pwd)/mcp_server/server.py

# Copier les hooks
mkdir -p ~/.claude/rlm/hooks
cp hooks/*.py ~/.claude/rlm/hooks/
chmod +x ~/.claude/rlm/hooks/*.py

# Copier le skill
mkdir -p ~/.claude/skills/rlm-analyze
cp templates/skills/rlm-analyze/skill.md ~/.claude/skills/rlm-analyze/

# Configurer les hooks dans ~/.claude/settings.json
# (voir templates/hooks_settings.json)
```

---

## Comment Ca Marche

### Architecture

```
+-------------------------------------------------------------------+
|                  RLM - Architecture v0.9.0                         |
+-------------------------------------------------------------------+
|                                                                    |
|  HOOKS CLAUDE CODE (2 hooks)                                      |
|  +--------------------------------------------------------------+ |
|  | Hook "PreCompact" (AVANT /compact ou auto-compact)           | |
|  |   -> pre_compact_chunk.py                                    | |
|  |   -> Cree un chunk automatique minimal                       | |
|  |   -> Sauvegarde garantie avant perte de contexte             | |
|  +--------------------------------------------------------------+ |
|  | Hook "PostToolUse" (apres rlm_chunk)                         | |
|  |   -> reset_chunk_counter.py (pour stats)                     | |
|  +--------------------------------------------------------------+ |
|                              |                                     |
|                              v                                     |
|  UTILISATEUR + CLAUDE                                             |
|    - User: "chunk ca", "garde en memoire", "rlm_remember"        |
|    - Claude: Propose chunk aux moments cles                       |
|    - Post-compact: Claude lit le chunk auto et enrichit          |
|                              |                                     |
|                              v                                     |
|  MCP SERVER RLM (14 tools)                                        |
|    - rlm_remember/recall/forget/status (insights)                |
|    - rlm_chunk/peek/grep/list_chunks + search/sessions (nav)     |
|    - rlm_retention_preview/run/restore (retention)               |
|    - Stockage persistant dans context/                           |
|                                                                    |
+-------------------------------------------------------------------+
```

### Strategie de Chunking (v0.9.0)

**Principe** : L'utilisateur decide, le systeme sauvegarde automatiquement avant /compact.

| Moment | Action | Declencheur |
|--------|--------|-------------|
| Instruction explicite | `rlm_chunk()` / `rlm_remember()` | Utilisateur |
| Moment cle | Claude propose de chunker | Reflexe Claude |
| `/compact` | Chunk automatique minimal | Hook PreCompact |
| Post-compact | Claude lit et enrichit | Reflexe Claude |

#### Hook PreCompact (SAUVEGARDE AUTO)

Avant `/compact` ou auto-compact â†’ chunk automatique cree :
- Resume basique de la session
- Tags: `auto,precompact`
- Claude peut enrichir apres le compact

#### Triggers Manuels (reflexe Claude)

- ğŸ¯ DÃ©cision prise
- âœ… TÃ¢che terminÃ©e
- ğŸ’¡ Insight dÃ©couvert
- ğŸ”„ Changement de sujet
- âš ï¸ Erreur corrigÃ©e

---

## Tools MCP Disponibles

### Phase 1 - Memory (Insights)

| Tool | Description |
|------|-------------|
| `rlm_remember` | Sauvegarder un insight (decision, fait, preference) |
| `rlm_recall` | Recuperer des insights par recherche ou categorie |
| `rlm_forget` | Supprimer un insight par ID |
| `rlm_status` | Stats du systeme (insights + chunks) |

### Phase 2 - Navigation (Chunks)

| Tool | Description |
|------|-------------|
| `rlm_chunk` | Sauvegarder du contenu en chunk externe |
| `rlm_peek` | Lire un chunk (ou portion par lignes) |
| `rlm_grep` | Chercher un pattern regex dans tous les chunks |
| `rlm_grep(..., fuzzy=True)` | **NEW v0.6.1** Recherche fuzzy tolerant les typos |
| `rlm_list_chunks` | Lister les chunks disponibles avec metadonnees |

### Phase 5.1 - Search (BM25)

| Tool | Description |
|------|-------------|
| `rlm_search` | Recherche BM25 par pertinence (FR/EN, accents normalises) |

### Phase 5.5 - Multi-sessions

| Tool | Description |
|------|-------------|
| `rlm_sessions` | Lister sessions par projet/domaine |
| `rlm_domains` | Lister domaines suggeres (31 domaines) |
| `rlm_grep` | + params `project=`, `domain=` pour filtrer |
| `rlm_search` | + params `project=`, `domain=` pour filtrer |

**Nouveau format chunk ID** : `{date}_{project}_{seq}[_{ticket}][_{domain}]`
- Exemple : `2026-01-18_RLM_001_r&d`
- Auto-detection du projet via git ou cwd
- Backward compat : chunks existants (format 1.0) restent accessibles

### Phase 5.6 - Retention (v0.7.0)

| Tool | Description |
|------|-------------|
| `rlm_retention_preview` | **NEW** Preview des actions archive/purge (dry-run) |
| `rlm_retention_run` | **NEW** Executer archivage et/ou purge |
| `rlm_restore` | **NEW** Restaurer un chunk archive |

**Architecture 3 zones** : ACTIF â†’ ARCHIVE (.gz) â†’ PURGE
- Archive apres 30 jours si `access_count == 0` et non-immune
- Purge apres 180 jours en archive
- Immunite : tags `critical`/`decision`, `access_count >= 3`, keywords `DECISION:`/`IMPORTANT:`
- Auto-restore : `peek()` restaure automatiquement les chunks archives

---

## Skills RLM

Claude utilise ces patterns automatiquement quand pertinent (aucune action humaine requise).

### /rlm-analyze

Analyser un chunk avec un sub-agent dedie (contexte isole).

### /rlm-parallel

Analyser plusieurs chunks en parallele et fusionner les resultats.
Pattern "Partition + Map" du paper MIT RLM.

- 3 analyses paralleles (Task tools Sonnet)
- 1 merger qui synthetise avec citations [chunk_id]
- Detection automatique des contradictions

---

## Usage

### Sauvegarder des insights

```python
# Sauvegarder une decision importante
rlm_remember("Le client prefere les formats 500ml",
             category="preference",
             importance="high",
             tags="client,format")

# Retrouver des insights
rlm_recall(query="client")           # Recherche par mot-cle
rlm_recall(category="decision")      # Filtrer par categorie
rlm_recall(importance="critical")    # Filtrer par importance
```

### Gerer l'historique de conversation

```python
# Sauvegarder une partie de conversation importante
rlm_chunk("Discussion sur le business plan... [contenu long]",
          summary="BP Joy Juice - Scenarios REA",
          tags="bp,scenario,2026")

# Phase 4: Auto-summary si pas de summary fourni
rlm_chunk("Mon contenu ici...", tags="auto")
# â†’ Summary auto-genere depuis la premiere ligne

# Phase 4: Detection des doublons
rlm_chunk("Meme contenu...")  # â†’ "Duplicate detected"

# Voir ce qui est stocke (avec access_count Phase 4)
rlm_list_chunks()

# Lire un chunk specifique (incremente access_count)
rlm_peek("2026-01-18_001")

# Chercher dans l'historique (regex)
rlm_grep("business plan")

# Phase 5.2: Recherche fuzzy (tolere les typos)
rlm_grep("buisness", fuzzy=True)           # â†’ trouve "business"
rlm_grep("validaton", fuzzy=True)          # â†’ trouve "validation"
rlm_grep("senario", fuzzy=True, fuzzy_threshold=70)  # Plus tolerant

# Phase 5.5c: Filtrer par projet/domaine
rlm_grep("equipment", project="JoyJuice", domain="bp")

# Recherche BM25 par pertinence (Phase 5)
rlm_search("discussion sur le business plan")
# â†’ Retourne les chunks tries par score de pertinence
# â†’ Supporte FR/EN, normalise les accents (realiste = rÃ©aliste)

# Phase 5.5c: Filtrer les recherches
rlm_search("scenarios", project="JoyJuice")

# Lister les sessions disponibles
rlm_sessions()                          # Toutes
rlm_sessions(project="RLM")             # Par projet
rlm_sessions(domain="bp")               # Par domaine

# Voir les domaines disponibles
rlm_domains()  # â†’ 31 domaines (23 Joy Juice + 8 default)
```

### Voir l'etat du systeme

```python
rlm_status()
# Output:
# RLM Memory Status (v1.0.0)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Insights: 5
#   By category: decision: 2, finding: 3
#   By importance: high: 3, medium: 2
# Chunks: 3 (~4500 tokens)
```

---

## Categories d'Insights

| Categorie | Usage |
|-----------|-------|
| `decision` | Decisions prises pendant la session |
| `fact` | Faits decouverts ou confirmes |
| `preference` | Preferences de l'utilisateur |
| `finding` | Decouvertes techniques |
| `todo` | Actions a faire |
| `general` | Autre |

## Niveaux d'Importance

- `low` : Info de contexte
- `medium` : Standard (defaut)
- `high` : Important a retenir
- `critical` : Ne jamais oublier

---

## Structure du Projet

```
RLM/
â”œâ”€â”€ mcp_server/
â”‚   â”œâ”€â”€ server.py              # Serveur MCP (14 tools)
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ memory.py          # Phase 1 (insights)
â”‚       â”œâ”€â”€ navigation.py      # Phase 2 + 5.5 (chunks + auto-restore)
â”‚       â”œâ”€â”€ tokenizer_fr.py    # Phase 5.1 (tokenization FR/EN)
â”‚       â”œâ”€â”€ search.py          # Phase 5.1 (BM25 search)
â”‚       â”œâ”€â”€ sessions.py        # Phase 5.5 (sessions, domains)
â”‚       â””â”€â”€ retention.py       # Phase 5.6 (archive/restore/purge)
â”‚
â”œâ”€â”€ hooks/                     # Phase 3+ (auto-chunking)
â”‚   â”œâ”€â”€ pre_compact_chunk.py   # Hook PreCompact - force chunk avant compact
â”‚   â”œâ”€â”€ auto_chunk_check.py    # Hook Stop - progressif + context-aware
â”‚   â””â”€â”€ reset_chunk_counter.py # Hook PostToolUse - reset compteur
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ hooks_settings.json    # Config hooks a copier
â”‚   â”œâ”€â”€ CLAUDE_RLM_SNIPPET.md  # Instructions CLAUDE.md
â”‚   â””â”€â”€ skills/
â”‚       â”œâ”€â”€ rlm-analyze/
â”‚       â”‚   â””â”€â”€ skill.md       # Skill analyse 1 chunk
â”‚       â””â”€â”€ rlm-parallel/
â”‚           â””â”€â”€ skill.md       # Skill analyse parallele
â”‚
â”œâ”€â”€ context/                   # Stockage (cree a l'install)
â”‚   â”œâ”€â”€ session_memory.json    # Insights stockes (local, git-ignored)
â”‚   â”œâ”€â”€ index.json             # Index des chunks (local, git-ignored)
â”‚   â”œâ”€â”€ sessions.json          # Index des sessions (local, git-ignored)
â”‚   â”œâ”€â”€ domains.json           # Domaines suggeres (local, auto-genere)
â”‚   â”œâ”€â”€ domains.json.example   # Exemple avec domaines Joy Juice
â”‚   â”œâ”€â”€ chunks/                # Historique decoupe
â”‚   â”œâ”€â”€ archive/               # Chunks archives .gz (Phase 5.6)
â”‚   â”œâ”€â”€ archive_index.json     # Index des archives (Phase 5.6)
â”‚   â””â”€â”€ purge_log.json         # Log des purges (Phase 5.6)
â”‚
â”œâ”€â”€ install.sh                 # Script installation
â”œâ”€â”€ README.md                  # Cette documentation
â”œâ”€â”€ SESSION_CONTEXT.md         # Contexte de reprise
â”œâ”€â”€ ROADMAP.md                 # Pistes futures
â””â”€â”€ docs/
    â”œâ”€â”€ STATE_OF_ART.md        # Recherche (RLM, Letta, TTT)
    â”œâ”€â”€ IMPLEMENTATION_PROPOSAL.md
    â””â”€â”€ CHECKLIST_PAPER_VS_SOLUTION.md
```

---

## Configuration

### Personnalisation des Domaines

Les domaines sont des suggestions pour organiser vos chunks par theme.
Un fichier `domains.json` generique est cree automatiquement au premier lancement.

Pour personnaliser :

```bash
# Voir l'exemple complet (Joy Juice)
cat context/domains.json.example

# Editer votre fichier local
nano context/domains.json
```

Structure du fichier :

```json
{
  "domains": {
    "mon_projet": {
      "description": "Domaines pour mon projet",
      "list": ["feature", "bugfix", "infra", "docs"]
    }
  }
}
```

Note : Vous pouvez utiliser n'importe quel domaine, meme s'il n'est pas dans la liste.

### Hooks Claude Code (v0.9.0)

Dans `~/.claude/settings.json` :

```json
{
  "hooks": {
    "PreCompact": [
      {
        "matcher": "manual",
        "hooks": [{
          "type": "command",
          "command": "python3 ~/.claude/rlm/hooks/pre_compact_chunk.py"
        }]
      },
      {
        "matcher": "auto",
        "hooks": [{
          "type": "command",
          "command": "python3 ~/.claude/rlm/hooks/pre_compact_chunk.py"
        }]
      }
    ],
    "PostToolUse": [{
      "matcher": "mcp__rlm-server__rlm_chunk",
      "hooks": [{
        "type": "command",
        "command": "python3 ~/.claude/rlm/hooks/reset_chunk_counter.py"
      }]
    }]
  }
}
```

**Notes** :
- `PreCompact` cree un chunk automatique avant /compact (manual ou auto)
- Hook `Stop` supprime en v0.9.0 (pas de reminders automatiques)
- L'utilisateur decide quand chunker, le systeme sauvegarde avant perte

---

## Troubleshooting

### "MCP server not found"

```bash
claude mcp list                    # Verifier les serveurs
claude mcp remove rlm-server       # Supprimer si existe
claude mcp add rlm-server -- python3 /path/to/mcp_server/server.py
```

### "Hooks ne fonctionnent pas"

```bash
# Tester manuellement
python3 ~/.claude/rlm/hooks/auto_chunk_check.py
cat ~/.claude/rlm/chunk_state.json

# Verifier settings.json
cat ~/.claude/settings.json | grep -A 10 "hooks"
```

### "Skill /rlm-analyze non trouve"

```bash
ls ~/.claude/skills/rlm-analyze/
# Doit contenir skill.md
```

---

## Roadmap

- [x] **Phase 1** : Memory tools (remember/recall/forget/status)
- [x] **Phase 2** : Navigation tools (chunk/peek/grep/list)
- [x] **Phase 3** : Auto-chunking + Skill /rlm-analyze
- [x] **Phase 4** : Production (auto-summary, dedup, access tracking)
- [x] **Phase 5** : Avance
  - [x] 5.1 : BM25 search (rlm_search)
  - [x] 5.2 : Fuzzy grep (v0.6.1 - tolere typos)
  - [x] 5.3 : Sub-agents paralleles (/rlm-parallel)
  - [x] 5.5 : Multi-sessions (sessions, domains, filtres project/domain)
  - [x] **5.6 : Retention** (v0.7.0 - archive/purge)
- [ ] **Phase 6** : Production-Ready (tests, CI/CD, PyPI)

Voir [ROADMAP.md](ROADMAP.md) pour les details.

---

## Documentation

| Fichier | Contenu |
|---------|---------|
| [STATE_OF_ART.md](STATE_OF_ART.md) | Etat de l'art (RLM, Letta, TTT-E2E) |
| [IMPLEMENTATION_PROPOSAL.md](IMPLEMENTATION_PROPOSAL.md) | Architecture detaillee |
| [CHECKLIST_PAPER_VS_SOLUTION.md](CHECKLIST_PAPER_VS_SOLUTION.md) | Couverture paper MIT (85%) |
| [SESSION_CONTEXT.md](SESSION_CONTEXT.md) | Contexte pour reprendre une session |
| [ROADMAP.md](ROADMAP.md) | Pistes futures |

---

## References

- [Paper RLM (MIT CSAIL)](https://arxiv.org/abs/2512.24601) - Zhang et al., Dec 2025
- [Prime Intellect Blog](https://www.primeintellect.ai/blog/rlm)
- [Letta/MemGPT](https://github.com/letta-ai/letta)
- [MCP Specification](https://modelcontextprotocol.io/specification)
- [Claude Code Hooks](https://docs.anthropic.com/claude-code/hooks)

---

## Auteurs

- Ahmed MAKNI ([@EncrEor](https://github.com/EncrEor))
- Claude Opus 4.5 (R&D conjointe)

## License

MIT License - voir [LICENSE](LICENSE)

---

**Derniere mise a jour** : 2026-01-24 (v0.9.0 - Systeme Simplifie User-Driven + Auto-Compact)
